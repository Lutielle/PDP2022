{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0775d15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import seaborn #as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pandas import read_csv\n",
    "pd.options.display.max_rows = 4000\n",
    "\n",
    "#read_csv reads csv into a pandas DataFrame\n",
    "#it uses the first line of the file as a header if header is undeclared\n",
    "    #i.e. as names = String(s)\n",
    "dataset = read_csv(\"C:\\\\Users\\\\Kai\\\\Documents\\\\Work\\\\ES5m-sma.txt\")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac49c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up X - capital implies 2D array - and y\n",
    "#These will be used in generating the prediction\n",
    "columnname = ['sma200', 'stoch100', 'rsi60', 'momentum20']\n",
    "X = dataset[columnname]\n",
    "\n",
    "y = dataset['direction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b42c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardizing and scaling X\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "standardizer = StandardScaler()\n",
    "X = standardizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6babc8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting X and y into training data and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size=0.25, shuffle=False)\n",
    "#random_state = 0 renders the randomization between iterations consistent, allowing for debugging/testing/detecting changes between runs\n",
    "#shuffle = False causes the data to be selected in order for use for testing, instead of random data points in the set (True is the default state)\n",
    "#setting shuffle = False decreases the accuracy of the prediction significantly, but using randomly ordered data generates outright incorrect values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbef68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These imports are for various prediction models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#We select the ones we want to use here\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train) #fit() is the training method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f3ee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate predictions using trained model\n",
    "prediction = model.predict(X_test)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b63ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate a confusion matrix to assess performance\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, prediction)\n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix(y_test, prediction).ravel()\n",
    "\n",
    "print('True Positive(TP)  = ', TP)\n",
    "print('False Positive(FP) = ', FP)\n",
    "print('True Negative(TN)  = ', TN)\n",
    "print('False Negative(FN) = ', FN)\n",
    "\n",
    "accuracy =  (TP+TN) /(TP+FP+TN+FN)\n",
    "\n",
    "print('Accuracy of the binary classification = {:0.3f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afc1cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading in each model\n",
    "\n",
    "models = {}\n",
    "\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "models['Logistic Regression'] = LogisticRegression()\n",
    "\n",
    "# Support Vector Machines\n",
    "from sklearn.svm import LinearSVC\n",
    "models['Support Vector Machines'] = LinearSVC()\n",
    "\n",
    "# Decision Trees\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "models['Decision Trees'] = DecisionTreeClassifier()\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "models['Random Forest'] = RandomForestClassifier()\n",
    "\n",
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "models['Naive Bayes'] = GaussianNB()\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "models['K-Nearest Neighbor'] = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97818e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating their accuracy, precision, and recall\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "accuracy, precision, recall = {}, {}, {}\n",
    "\n",
    "for key in models.keys():\n",
    "    \n",
    "    # Fit the classifier model\n",
    "    models[key].fit(X_train, y_train)\n",
    "    \n",
    "    # Prediction \n",
    "    predictions = models[key].predict(X_test)\n",
    "    \n",
    "    # Calculate Accuracy, Precision and Recall Metrics\n",
    "    accuracy[key] = accuracy_score(predictions, y_test)\n",
    "    precision[key] = precision_score(predictions, y_test)\n",
    "    recall[key] = recall_score(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db24bcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing assessments of each model\n",
    "df_model = pd.DataFrame(index=models.keys(), columns=['Accuracy', 'Precision', 'Recall'])\n",
    "df_model['Accuracy'] = accuracy.values()\n",
    "df_model['Precision'] = precision.values()\n",
    "df_model['Recall'] = recall.values()\n",
    "\n",
    "df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf7fabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Time for Graphing!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae57d33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
